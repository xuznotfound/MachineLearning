
"""
æ”¹è¿›ç‰ˆLSTMæ¨¡å‹
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, regularizers
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import os
from datetime import datetime

# è®¾ç½®GPU
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)

tf.random.set_seed(42)
np.random.seed(42)

print("=" * 70)
print("æ”¹è¿›ç‰ˆLSTMæ¨¡å‹ - å¾·é‡Œæ°”å€™æ¸©åº¦é¢„æµ‹")
print("=" * 70)

# 1. æ”¹è¿›çš„æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
def load_and_preprocess():
    """æ”¹è¿›çš„æ•°æ®åŠ è½½"""
    train_path = '../data/DailyDelhiClimateTrain.csv'
    test_path = '../data/DailyDelhiClimateTest.csv'
    
    train = pd.read_csv(train_path)
    test = pd.read_csv(test_path)
    
    # åˆå¹¶æ•°æ®ç”¨äºç»Ÿä¸€é¢„å¤„ç†
    combined = pd.concat([train, test], ignore_index=True)
    combined['date'] = pd.to_datetime(combined['date'])
    combined = combined.sort_values('date').reset_index(drop=True)
    
    print(f"æ€»æ•°æ®é‡: {len(combined)} å¤©")
    print(f"è®­ç»ƒé›†: {len(train)} å¤© ({len(train)/len(combined)*100:.1f}%)")
    print(f"æµ‹è¯•é›†: {len(test)} å¤© ({len(test)/len(combined)*100:.1f}%)")
    
    return combined, len(train)

# 2. æ”¹è¿›çš„åºåˆ—åˆ›å»ºï¼ˆæ·»åŠ ç‰¹å¾å·¥ç¨‹ï¼‰
def create_enhanced_sequences(df, window_size=14):
    """åˆ›å»ºå¢å¼ºçš„æ—¶é—´åºåˆ—"""
    
    # åŸºç¡€ç‰¹å¾
    base_features = ['humidity', 'meanpressure', 'wind_speed']
    
    # åˆ›å»ºæ–°ç‰¹å¾
    df_features = df.copy()
    
    # å­£èŠ‚æ€§ç‰¹å¾
    df_features['month'] = df_features['date'].dt.month
    df_features['day_of_year'] = df_features['date'].dt.dayofyear
    
    # æ¸©åº¦æ»åç‰¹å¾ï¼ˆå‰1å¤©ã€å‰7å¤©ï¼‰
    df_features['temp_lag1'] = df_features['meantemp'].shift(1)
    df_features['temp_lag7'] = df_features['meantemp'].shift(7)
    
    # æ»‘åŠ¨çª—å£ç»Ÿè®¡
    df_features['temp_rolling_mean_7'] = df_features['meantemp'].rolling(window=7).mean()
    df_features['humidity_rolling_mean_7'] = df_features['humidity'].rolling(window=7).mean()
    
    # å¡«å……NaNå€¼
    df_features = df_features.fillna(method='bfill').fillna(method='ffill')
    
    # æœ€ç»ˆç‰¹å¾é›†
    features = base_features + ['month', 'day_of_year', 'temp_lag1', 'temp_lag7']
    
    print(f"ä½¿ç”¨ {len(features)} ä¸ªç‰¹å¾: {features}")
    
    # åˆ›å»ºåºåˆ—
    X, y = [], []
    for i in range(window_size, len(df_features)):
        X.append(df_features[features].iloc[i-window_size:i].values)
        y.append(df_features['meantemp'].iloc[i])
    
    return np.array(X), np.array(y), features

# 3. æ”¹è¿›çš„LSTMæ¨¡å‹æ¶æ„
def build_improved_lstm(input_shape):
    """æ„å»ºæ”¹è¿›çš„LSTMæ¨¡å‹"""
    model = keras.Sequential([
        keras.Input(shape=input_shape),
        
        # ç¬¬ä¸€å±‚LSTM
        layers.LSTM(128, return_sequences=True,
                   kernel_regularizer=regularizers.l2(0.001)),
        layers.BatchNormalization(),
        layers.Dropout(0.3),
        
        # ç¬¬äºŒå±‚LSTM
        layers.LSTM(64, return_sequences=True,
                   kernel_regularizer=regularizers.l2(0.001)),
        layers.BatchNormalization(),
        layers.Dropout(0.3),
        
        # ç¬¬ä¸‰å±‚LSTM
        layers.LSTM(32, return_sequences=False,
                   kernel_regularizer=regularizers.l2(0.001)),
        layers.BatchNormalization(),
        layers.Dropout(0.3),
        
        # å…¨è¿æ¥å±‚
        layers.Dense(32, activation='relu',
                    kernel_regularizer=regularizers.l2(0.001)),
        layers.Dropout(0.2),
        layers.Dense(16, activation='relu'),
        layers.Dense(1)  # è¾“å‡ºå±‚
    ])
    
    # ä½¿ç”¨è‡ªé€‚åº”å­¦ä¹ ç‡
    optimizer = keras.optimizers.Adam(
        learning_rate=0.001,
        beta_1=0.9,
        beta_2=0.999,
        epsilon=1e-07
    )
    
    model.compile(
        optimizer=optimizer,
        loss='mse',
        metrics=['mae', 'mse']
    )
    
    return model

# 4. æ”¹è¿›çš„è®­ç»ƒæµç¨‹
def train_improved_model():
    """æ”¹è¿›çš„è®­ç»ƒæµç¨‹"""
    
    # åŠ è½½æ•°æ®
    print("\n[1/6] åŠ è½½æ•°æ®...")
    combined, train_size = load_and_preprocess()
    
    # åˆ›å»ºåºåˆ—
    print("\n[2/6] åˆ›å»ºæ—¶é—´åºåˆ—...")
    window_size = 14  # å¢åŠ åˆ°14å¤©çª—å£
    X, y, features = create_enhanced_sequences(combined, window_size)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    # æ³¨æ„ï¼šæµ‹è¯•é›†æ˜¯åŸå§‹æµ‹è¯•é›†éƒ¨åˆ†ï¼Œä½†è¦è€ƒè™‘çª—å£åç§»
    X_train = X[:train_size - window_size]
    y_train = y[:train_size - window_size]
    X_test = X[train_size - window_size:]
    y_test = y[train_size - window_size:]
    
    print(f"\nè®­ç»ƒé›†: {X_train.shape}")
    print(f"æµ‹è¯•é›†: {X_test.shape}")
    
    # å½’ä¸€åŒ–ï¼ˆåªåœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆï¼‰
    print("\n[3/6] æ•°æ®å½’ä¸€åŒ–...")
    scaler_X = MinMaxScaler()
    scaler_y = MinMaxScaler()
    
    # é‡å¡‘è®­ç»ƒæ•°æ®è¿›è¡Œå½’ä¸€åŒ–
    X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])
    X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])
    
    X_train_scaled = scaler_X.fit_transform(X_train_reshaped).reshape(X_train.shape)
    X_test_scaled = scaler_X.transform(X_test_reshaped).reshape(X_test.shape)
    
    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()
    y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()
    
    # æ„å»ºæ¨¡å‹
    print("\n[4/6] æ„å»ºæ”¹è¿›çš„LSTMæ¨¡å‹...")
    input_shape = (window_size, len(features))
    model = build_improved_lstm(input_shape)
    model.summary()
    
    # æ”¹è¿›çš„å›è°ƒå‡½æ•°
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=25,
            restore_best_weights=True,
            verbose=1
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=10,
            min_lr=1e-6,
            verbose=1
        ),
        keras.callbacks.ModelCheckpoint(
            '../models/lstm_improved_best.h5',
            monitor='val_loss',
            save_best_only=True,
            verbose=1
        )
    ]
    
    # è®­ç»ƒæ¨¡å‹
    print("\n[5/6] å¼€å§‹è®­ç»ƒ...")
    history = model.fit(
        X_train_scaled, y_train_scaled,
        batch_size=32,
        epochs=200,  # å¢åŠ epochæ•°
        validation_split=0.2,
        callbacks=callbacks,
        verbose=1
    )
    
    # è¯„ä¼°æ¨¡å‹
    print("\n[6/6] è¯„ä¼°æ¨¡å‹...")
    test_loss, test_mae, test_mse = model.evaluate(X_test_scaled, y_test_scaled, verbose=0)
    
    # é¢„æµ‹
    y_pred_scaled = model.predict(X_test_scaled, verbose=0).flatten()
    
    # åå½’ä¸€åŒ–
    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
    y_test_original = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()
    
    # è®¡ç®—æŒ‡æ ‡
    mse = mean_squared_error(y_test_original, y_pred)
    mae = mean_absolute_error(y_test_original, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test_original, y_pred)
    
    print(f"\nğŸ“Š æ”¹è¿›æ¨¡å‹æµ‹è¯•ç»“æœ:")
    print(f"  MSE: {mse:.4f} (Â°C)Â²")
    print(f"  RMSE: {rmse:.4f} Â°C")
    print(f"  MAE: {mae:.4f} Â°C")
    print(f"  RÂ²: {r2:.4f}")
    
    # å¯è§†åŒ–
    visualize_results(y_test_original, y_pred, history, mse)
    
    return mse, model

def visualize_results(y_true, y_pred, history, mse):
    """å¯è§†åŒ–ç»“æœ"""
    os.makedirs('../results', exist_ok=True)
    
    # è®­ç»ƒå†å²
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    axes[0, 0].plot(history.history['loss'], label='è®­ç»ƒæŸå¤±')
    axes[0, 0].plot(history.history['val_loss'], label='éªŒè¯æŸå¤±')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('æŸå¤±')
    axes[0, 0].set_title('è®­ç»ƒå†å² - æŸå¤±')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    axes[0, 1].plot(history.history['mae'], label='è®­ç»ƒMAE')
    axes[0, 1].plot(history.history['val_mae'], label='éªŒè¯MAE')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('MAE (Â°C)')
    axes[0, 1].set_title('è®­ç»ƒå†å² - MAE')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # é¢„æµ‹å¯¹æ¯”
    axes[0, 2].plot(y_true[:100], label='çœŸå®æ¸©åº¦', linewidth=2)
    axes[0, 2].plot(y_pred[:100], label='é¢„æµ‹æ¸©åº¦', linewidth=2)
    axes[0, 2].set_xlabel('æ ·æœ¬ç´¢å¼•')
    axes[0, 2].set_ylabel('æ¸©åº¦ (Â°C)')
    axes[0, 2].set_title(f'é¢„æµ‹å¯¹æ¯” (MSE={mse:.2f})')
    axes[0, 2].legend()
    axes[0, 2].grid(True, alpha=0.3)
    
    # æ•£ç‚¹å›¾
    axes[1, 0].scatter(y_true, y_pred, alpha=0.5, s=10)
    min_val = min(y_true.min(), y_pred.min())
    max_val = max(y_true.max(), y_pred.max())
    axes[1, 0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)
    axes[1, 0].set_xlabel('çœŸå®æ¸©åº¦ (Â°C)')
    axes[1, 0].set_ylabel('é¢„æµ‹æ¸©åº¦ (Â°C)')
    axes[1, 0].set_title('çœŸå®å€¼ vs é¢„æµ‹å€¼')
    axes[1, 0].grid(True, alpha=0.3)
    
    # è¯¯å·®åˆ†å¸ƒ
    errors = y_true - y_pred
    axes[1, 1].hist(errors, bins=30, edgecolor='black', alpha=0.7)
    axes[1, 1].axvline(x=0, color='r', linestyle='--', linewidth=2)
    axes[1, 1].set_xlabel('é¢„æµ‹è¯¯å·® (Â°C)')
    axes[1, 1].set_ylabel('é¢‘æ•°')
    axes[1, 1].set_title(f'è¯¯å·®åˆ†å¸ƒ (å‡å€¼={errors.mean():.2f}Â°C)')
    axes[1, 1].grid(True, alpha=0.3)
    
    # æ®‹å·®å›¾
    axes[1, 2].scatter(y_pred, errors, alpha=0.5, s=10)
    axes[1, 2].axhline(y=0, color='r', linestyle='--', linewidth=2)
    axes[1, 2].set_xlabel('é¢„æµ‹æ¸©åº¦ (Â°C)')
    axes[1, 2].set_ylabel('æ®‹å·® (Â°C)')
    axes[1, 2].set_title('æ®‹å·®å›¾')
    axes[1, 2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('../results/lstm_improved_results.png', dpi=150, bbox_inches='tight')
    plt.show()
    
    # ä¿å­˜é¢„æµ‹ç»“æœ
    results_df = pd.DataFrame({
        'çœŸå®æ¸©åº¦': y_true,
        'é¢„æµ‹æ¸©åº¦': y_pred,
        'è¯¯å·®': errors
    })
    results_df.to_csv('../results/lstm_predictions.csv', index=False)

if __name__ == "__main__":
    try:
        print("å¼€å§‹è®­ç»ƒæ”¹è¿›ç‰ˆLSTMæ¨¡å‹...")
        mse, model = train_improved_model()
        print(f"\nâœ… æ”¹è¿›ç‰ˆè®­ç»ƒå®Œæˆï¼æµ‹è¯•é›†MSE: {mse:.4f} (Â°C)Â²")
        
        # ä¿å­˜æ¨¡å‹
        model.save('../models/lstm_improved_final.h5')
        print(f"æ¨¡å‹å·²ä¿å­˜: ../models/lstm_improved_final.h5")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
'''
ç»“æœï¼š
  MSE: 6.9457 (Â°C)Â²
  RMSE: 2.6355 Â°C
  MAE: 2.2653 Â°C
  RÂ²: 0.8268
'''